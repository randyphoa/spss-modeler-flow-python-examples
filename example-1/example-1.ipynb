{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2a03e4e-4c49-4f31-be98-c65a7c69a7eb"
   },
   "source": [
    "# Example 1: Build models using Python libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bf96f77-d9b4-4d06-bcea-a2d4bba82808"
   },
   "source": [
    "## Use case\n",
    "\n",
    "A business user with minimal programming knowledge wants to visually apply some complex business rules during the data preparation stage for different business scenarios and train a LightGBM model which is not available out of the box at the time of writing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d269482-e102-4af2-b4c6-9a9848c8af35"
   },
   "source": [
    "## Build Syntax in Extension Model node\n",
    "\n",
    "Copy and the below code to the Build Syntax section of Extension Model node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9f6d286-abbf-4d88-a2c2-8657f3ace2d1"
   },
   "outputs": [],
   "source": [
    "# install the required Python libraries\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pandas\", \"ibm-watson-machine-learning\", \"scikit-learn\", \"lightgbm\", \"--no-input\"])\n",
    "\n",
    "import spss.pyspark.runtime\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cxt = spss.pyspark.runtime.getContext()\n",
    "df = cxt.getSparkInputData().toPandas()\n",
    "\n",
    "# build a simple lightgbm model\n",
    "\n",
    "target = \"MortgageDefault\"\n",
    "y = df[target]\n",
    "X = df.drop(target, axis=1)\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (OneHotEncoder(), make_column_selector(dtype_include=object)),\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[(\"transform\", ct), (\"clf\", lgb.LGBMClassifier(objective=\"binary\"))])\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# save the model for scoring\n",
    "joblib.dump(pipeline, \"/tmp/pipeline.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df432a60-ca8d-47de-9476-162320bc4182"
   },
   "source": [
    "## Score Syntax in Extension Model node\n",
    "\n",
    "Copy and the below code to the Build Syntax section of Extension Model node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eb253fc-751a-477a-b5b8-dc2b72d280e2"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pandas\", \"ibm-watson-machine-learning\", \"scikit-learn\", \"lightgbm\", \"--no-input\"])\n",
    "\n",
    "import spss.pyspark.runtime\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "import joblib\n",
    "\n",
    "cxt = spss.pyspark.runtime.getContext()\n",
    "sqlContext = cxt.getSparkSQLContext()\n",
    "\n",
    "target = \"MortgageDefault\"\n",
    "prediction = f\"$PRED-{target}\"\n",
    "probability = f\"$PROB-{target}\"\n",
    "\n",
    "fieldList = [StructField(x.name, x.dataType, x.nullable) for x in cxt.getSparkInputSchema()]\n",
    "fieldList.append(StructField(prediction, StringType(), nullable=False))\n",
    "fieldList.append(StructField(probability, FloatType(), nullable=False))\n",
    "outputSchema = StructType(fieldList)\n",
    "cxt.setSparkOutputSchema(outputSchema)\n",
    "\n",
    "if not cxt.isComputeDataModelOnly():\n",
    "    df = cxt.getSparkInputData().toPandas()\n",
    "    pipeline = joblib.load(\"/tmp/pipeline.pkl\") \n",
    "    df[prediction] = pipeline.predict(df)\n",
    "    df[probability] = pipeline.predict_proba(df)[:,-1]\n",
    "    cxt.setSparkOutputData(sqlContext.createDataFrame(df))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4cce46d6be9934fbd27f9ca0432556941ea5bdf741d4f4d64c6cd7f8dfa8fba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
